/**
 * server/utils/prober.js - ç½‘ç›˜ä¼˜åŒ–ç‰ˆ
 * åªè¯»å–éŸ³é¢‘æ–‡ä»¶å¤´éƒ¨ï¼ˆå‰ 5MBï¼‰ï¼Œå¤§å¹…å‡å°‘ç½‘ç»œä¼ è¾“
 */

const fs = require('fs').promises
const fsSync = require('fs')
const Path = require('path')
const os = require('os')
const { promisify } = require('util')
const { pipeline } = require('stream')
const pipelineAsync = promisify(pipeline)

const Logger = require('../Logger')
const { secondsToTimestamp } = require('./index')
const ProbeCache = require('../scanner/ProbeCache')
const scanConfig = require('../scanner/scanConfig')

class Prober {
  constructor() {
    this.FFProbePath = process.env.FFPROBE_PATH || 'ffprobe'
    this.TempProbeDir = Path.join(os.tmpdir(), 'abs-probe-cache')
  }

  /**
   * ç¡®ä¿ä¸´æ—¶ç›®å½•å­˜åœ¨
   */
  async ensureTempDir() {
    try {
      await fs.mkdir(this.TempProbeDir, { recursive: true })
    } catch (err) {
      Logger.error('[Prober] Failed to create temp dir:', err)
    }
  }

  /**
   * ğŸš€ æ ¸å¿ƒä¼˜åŒ–ï¼šåªè¯»å–æ–‡ä»¶å‰ N MB
   * å¤§å¤šæ•°éŸ³é¢‘æ ¼å¼çš„å…ƒæ•°æ®éƒ½åœ¨æ–‡ä»¶å¤´éƒ¨
   */
  async readPartialFile(filePath, maxBytes = 5 * 1024 * 1024) {
    const tempFile = Path.join(
      this.TempProbeDir, 
      `${Path.basename(filePath)}_${Date.now()}.tmp`
    )
    
    try {
      await this.ensureTempDir()
      
      // æ£€æŸ¥æ–‡ä»¶å¤§å°
      const stats = await fs.stat(filePath)
      const bytesToRead = Math.min(stats.size, maxBytes)
      
      Logger.debug(`[Prober] Reading first ${(bytesToRead / 1024 / 1024).toFixed(2)}MB of "${Path.basename(filePath)}"`)
      
      // åªè¯»å–å‰é¢éƒ¨åˆ†
      const readStream = fsSync.createReadStream(filePath, {
        start: 0,
        end: bytesToRead - 1
      })
      
      const writeStream = fsSync.createWriteStream(tempFile)
      
      await pipelineAsync(readStream, writeStream)
      
      return tempFile
    } catch (err) {
      Logger.error(`[Prober] Failed to read partial file "${filePath}":`, err.message)
      throw err
    }
  }

  /**
   * æ¸…ç†ä¸´æ—¶æ–‡ä»¶
   */
  async cleanupTempFile(tempFile) {
    try {
      if (tempFile && tempFile.includes(this.TempProbeDir)) {
        await fs.unlink(tempFile)
      }
    } catch (err) {
      // å¿½ç•¥æ¸…ç†é”™è¯¯
    }
  }

  /**
   * ä¼˜åŒ–çš„ probe æ–¹æ³•
   */
  async probe(filePath) {
    // 1. å°è¯•ä»ç¼“å­˜è·å–
    if (scanConfig.shouldUseCache()) {
      const cached = await ProbeCache.get(filePath)
      if (cached) {
        return cached
      }
    }

    let tempFile = null
    let usePartialRead = scanConfig.USE_PARTIAL_READ !== false // é»˜è®¤å¯ç”¨

    try {
      let targetFile = filePath

      // 2. å¦‚æœå¯ç”¨éƒ¨åˆ†è¯»å–ï¼Œåªè¯»å–æ–‡ä»¶å¤´éƒ¨
      if (usePartialRead) {
        try {
          const maxBytes = scanConfig.PARTIAL_READ_SIZE || 5 * 1024 * 1024 // é»˜è®¤ 5MB
          tempFile = await this.readPartialFile(filePath, maxBytes)
          targetFile = tempFile
          Logger.debug(`[Prober] Using partial read for "${Path.basename(filePath)}"`)
        } catch (err) {
          Logger.warn(`[Prober] Partial read failed, falling back to full file: ${err.message}`)
          targetFile = filePath
          tempFile = null
        }
      }

      // 3. è¿è¡Œ ffprobeï¼ˆä½¿ç”¨ä¼˜åŒ–å‚æ•°ï¼‰
      const result = await this.runFFProbe(targetFile)

      // 4. ç¼“å­˜ç»“æœ
      if (scanConfig.shouldUseCache() && result) {
        await ProbeCache.set(filePath, result)
      }

      return result
    } catch (err) {
      Logger.error(`[Prober] Failed to probe "${filePath}":`, err.message)
      return { error: err.message }
    } finally {
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      if (tempFile) {
        await this.cleanupTempFile(tempFile)
      }
    }
  }

  /**
   * è¿è¡Œ ffprobeï¼ˆä¼˜åŒ–å‚æ•°ï¼‰
   */
  async runFFProbe(filePath) {
    const { execFile } = require('child_process')
    const execFilePromise = promisify(execFile)

    // ä¼˜åŒ–çš„ ffprobe å‚æ•°
    const args = [
      '-v', 'quiet',
      '-print_format', 'json',
      '-show_format',
      '-show_streams',
      '-show_chapters',
      // ğŸš€ å…³é”®ä¼˜åŒ–ï¼šé™åˆ¶åˆ†ææ—¶é•¿å’Œæ¢æµ‹å¤§å°
      '-analyzeduration', scanConfig.FFPROBE_ANALYZE_DURATION || '5000000', // 5 ç§’
      '-probesize', scanConfig.FFPROBE_PROBE_SIZE || '5000000',             // 5MB
      filePath
    ]

    const timeout = scanConfig.PROBE_TIMEOUT || 30000

    try {
      const { stdout } = await execFilePromise(this.FFProbePath, args, {
        timeout,
        maxBuffer: 10 * 1024 * 1024 // 10MB buffer
      })

      const rawProbeData = JSON.parse(stdout)
      return this.parseProbeData(rawProbeData)
    } catch (err) {
      throw new Error(`FFProbe failed: ${err.message}`)
    }
  }

  /**
   * è§£æ ffprobe è¾“å‡º
   */
  parseProbeData(rawData) {
    if (!rawData || !rawData.format) {
      throw new Error('Invalid ffprobe output')
    }

    const audioStream = rawData.streams?.find(s => s.codec_type === 'audio')
    const videoStream = rawData.streams?.find(s => s.codec_type === 'video')

    if (!audioStream) {
      throw new Error('No audio stream found')
    }

    // æå–åŸºæœ¬ä¿¡æ¯
    const probeData = {
      format: rawData.format.format_name,
      duration: parseFloat(rawData.format.duration) || 0,
      size: parseInt(rawData.format.size) || 0,
      bit_rate: parseInt(rawData.format.bit_rate) || 0,
      
      audio_stream: {
        codec: audioStream.codec_name,
        bit_rate: parseInt(audioStream.bit_rate) || 0,
        channels: audioStream.channels,
        channel_layout: audioStream.channel_layout,
        sample_rate: audioStream.sample_rate,
        time_base: audioStream.time_base,
        language: audioStream.tags?.language
      },

      video_stream: videoStream ? {
        codec: videoStream.codec_name
      } : null,

      // ğŸš€ å¿«é€Ÿæ¨¡å¼ï¼šè·³è¿‡å…ƒæ•°æ®æ ‡ç­¾
      tags: scanConfig.shouldSkipMetadata() ? {} : this.parseTags(rawData.format.tags),
      
      chapters: this.parseChapters(rawData.chapters)
    }

    return probeData
  }

  /**
   * è§£ææ ‡ç­¾ï¼ˆå¯é€‰ï¼‰
   */
  parseTags(tags) {
    if (!tags || scanConfig.shouldSkipMetadata()) {
      return {}
    }

    // æ ‡å‡†åŒ–æ ‡ç­¾åç§°
    const normalized = {}
    for (const key in tags) {
      const lowerKey = key.toLowerCase()
      normalized[lowerKey] = tags[key]
    }

    return {
      tagTitle: normalized.title,
      tagAlbum: normalized.album,
      tagArtist: normalized.artist,
      tagAlbumArtist: normalized.album_artist || normalized['album-artist'],
      tagGenre: normalized.genre,
      tagDate: normalized.date || normalized.year,
      tagComposer: normalized.composer,
      tagComment: normalized.comment,
      tagDescription: normalized.description,
      tagPublisher: normalized.publisher,
      tagSubtitle: normalized.subtitle,
      tagTrack: normalized.track,
      tagDisc: normalized.disc,
      tagLanguage: normalized.language,
      tagISBN: normalized.isbn,
      tagASIN: normalized.asin,
      tagSeries: normalized.series,
      tagSeriesPart: normalized['series-part'] || normalized.series_part
    }
  }

  /**
   * è§£æç« èŠ‚
   */
  parseChapters(chapters) {
    if (!chapters || !chapters.length) {
      return []
    }

    return chapters.map((ch, index) => ({
      id: index,
      start: parseFloat(ch.start_time) || 0,
      end: parseFloat(ch.end_time) || 0,
      title: ch.tags?.title || `Chapter ${index + 1}`
    }))
  }

  /**
   * åŸå§‹ probe æ–¹æ³•ï¼ˆç”¨äºæµ‹è¯•ï¼‰
   */
  async rawProbe(filePath) {
    return this.runFFProbe(filePath)
  }
}

// å®šæœŸæ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆæ¯å°æ—¶ï¼‰
setInterval(async () => {
  try {
    const tempDir = new Prober().TempProbeDir
    const files = await fs.readdir(tempDir)
    const now = Date.now()
    
    for (const file of files) {
      const filePath = Path.join(tempDir, file)
      const stats = await fs.stat(filePath)
      
      // åˆ é™¤ 1 å°æ—¶å‰çš„ä¸´æ—¶æ–‡ä»¶
      if (now - stats.mtimeMs > 60 * 60 * 1000) {
        await fs.unlink(filePath)
      }
    }
  } catch (err) {
    // å¿½ç•¥æ¸…ç†é”™è¯¯
  }
}, 60 * 60 * 1000) // æ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡

module.exports = new Prober()
